{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "graduate-hands",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import missingno as msgn\n",
    "import time\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from pandas_profiling import ProfileReport\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.feature_selection import f_classif\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.metrics import *\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, PowerTransformer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_validate, StratifiedKFold, train_test_split, cross_val_score\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.feature_selection import SelectKBest, mutual_info_classif, f_classif\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix, ConfusionMatrixDisplay, f1_score\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import VotingClassifier, StackingClassifier\n",
    "\n",
    "import sklearn\n",
    "from tqdm import tqdm\n",
    "from sklearn.base import ClassifierMixin\n",
    "from sklearn.utils.testing import all_estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "antique-prescription",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle('df_v1_01.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "natural-italian",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "order_date                                  0\n",
       "user_id                                     0\n",
       "is_elite_user                               0\n",
       "supplier_id                                 0\n",
       "order_line_item_id                          0\n",
       "                                       ...   \n",
       "WEB_qa-supplier                       7642121\n",
       "rate_reviews-supplier                  450920\n",
       "review_like_count_reviews-supplier     450920\n",
       "pos_comment_reviews-supplier           450920\n",
       "neg_comment_reviews-supplier           450920\n",
       "Length: 78, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "lined-generator",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_date</th>\n",
       "      <th>user_id</th>\n",
       "      <th>is_elite_user</th>\n",
       "      <th>supplier_id</th>\n",
       "      <th>order_line_item_id</th>\n",
       "      <th>order_parent_id</th>\n",
       "      <th>product_variant_id</th>\n",
       "      <th>original_price</th>\n",
       "      <th>discounted_price</th>\n",
       "      <th>ship_cost</th>\n",
       "      <th>...</th>\n",
       "      <th>pos_answers_qa-supplier</th>\n",
       "      <th>neg_answers_qa-supplier</th>\n",
       "      <th>ANDROID_qa-supplier</th>\n",
       "      <th>IOS_qa-supplier</th>\n",
       "      <th>MOBILE_WEB_qa-supplier</th>\n",
       "      <th>WEB_qa-supplier</th>\n",
       "      <th>rate_reviews-supplier</th>\n",
       "      <th>review_like_count_reviews-supplier</th>\n",
       "      <th>pos_comment_reviews-supplier</th>\n",
       "      <th>neg_comment_reviews-supplier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-05-19 01:27:28.768000+00:00</td>\n",
       "      <td>2141</td>\n",
       "      <td>0</td>\n",
       "      <td>216503</td>\n",
       "      <td>955598029</td>\n",
       "      <td>625610651</td>\n",
       "      <td>133066437</td>\n",
       "      <td>104.900002</td>\n",
       "      <td>69.900002</td>\n",
       "      <td>11.33</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-05-19 01:27:28.768000+00:00</td>\n",
       "      <td>2141</td>\n",
       "      <td>0</td>\n",
       "      <td>1188</td>\n",
       "      <td>955598030</td>\n",
       "      <td>625610651</td>\n",
       "      <td>77047570</td>\n",
       "      <td>79.989998</td>\n",
       "      <td>79.989998</td>\n",
       "      <td>8.88</td>\n",
       "      <td>...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.736842</td>\n",
       "      <td>24.0</td>\n",
       "      <td>2.026316</td>\n",
       "      <td>1.197368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-06-02 00:51:35.862000+00:00</td>\n",
       "      <td>2141</td>\n",
       "      <td>0</td>\n",
       "      <td>200788</td>\n",
       "      <td>988146564</td>\n",
       "      <td>643936439</td>\n",
       "      <td>153411316</td>\n",
       "      <td>110.300003</td>\n",
       "      <td>55.150002</td>\n",
       "      <td>8.88</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-06-02 00:51:35.862000+00:00</td>\n",
       "      <td>2141</td>\n",
       "      <td>0</td>\n",
       "      <td>107296</td>\n",
       "      <td>988146563</td>\n",
       "      <td>643936439</td>\n",
       "      <td>172744639</td>\n",
       "      <td>59.900002</td>\n",
       "      <td>49.900002</td>\n",
       "      <td>8.88</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.450000</td>\n",
       "      <td>43.0</td>\n",
       "      <td>1.933333</td>\n",
       "      <td>0.933333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-06-09 23:31:37.963000+00:00</td>\n",
       "      <td>2141</td>\n",
       "      <td>0</td>\n",
       "      <td>968</td>\n",
       "      <td>1007223734</td>\n",
       "      <td>654756664</td>\n",
       "      <td>162306389</td>\n",
       "      <td>119.989998</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>9.40</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.384615</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.807692</td>\n",
       "      <td>0.923077</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 78 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        order_date  user_id  is_elite_user  supplier_id  \\\n",
       "0 2021-05-19 01:27:28.768000+00:00     2141              0       216503   \n",
       "1 2021-05-19 01:27:28.768000+00:00     2141              0         1188   \n",
       "2 2021-06-02 00:51:35.862000+00:00     2141              0       200788   \n",
       "3 2021-06-02 00:51:35.862000+00:00     2141              0       107296   \n",
       "4 2021-06-09 23:31:37.963000+00:00     2141              0          968   \n",
       "\n",
       "   order_line_item_id  order_parent_id  product_variant_id  original_price  \\\n",
       "0           955598029        625610651           133066437      104.900002   \n",
       "1           955598030        625610651            77047570       79.989998   \n",
       "2           988146564        643936439           153411316      110.300003   \n",
       "3           988146563        643936439           172744639       59.900002   \n",
       "4          1007223734        654756664           162306389      119.989998   \n",
       "\n",
       "   discounted_price  ship_cost  ... pos_answers_qa-supplier  \\\n",
       "0         69.900002      11.33  ...                     NaN   \n",
       "1         79.989998       8.88  ...                     7.0   \n",
       "2         55.150002       8.88  ...                     NaN   \n",
       "3         49.900002       8.88  ...                     3.0   \n",
       "4         48.000000       9.40  ...                     NaN   \n",
       "\n",
       "   neg_answers_qa-supplier ANDROID_qa-supplier  IOS_qa-supplier  \\\n",
       "0                      NaN                 NaN              NaN   \n",
       "1                      0.0                 2.0              0.0   \n",
       "2                      NaN                 NaN              NaN   \n",
       "3                      6.0                 5.0              7.0   \n",
       "4                      NaN                 NaN              NaN   \n",
       "\n",
       "  MOBILE_WEB_qa-supplier WEB_qa-supplier  rate_reviews-supplier  \\\n",
       "0                    NaN             NaN                    NaN   \n",
       "1                    0.0             0.0               4.736842   \n",
       "2                    NaN             NaN               5.000000   \n",
       "3                    0.0             0.0               4.450000   \n",
       "4                    NaN             NaN               4.384615   \n",
       "\n",
       "   review_like_count_reviews-supplier pos_comment_reviews-supplier  \\\n",
       "0                                 NaN                          NaN   \n",
       "1                                24.0                     2.026316   \n",
       "2                                 0.0                     1.000000   \n",
       "3                                43.0                     1.933333   \n",
       "4                                 1.0                     1.807692   \n",
       "\n",
       "   neg_comment_reviews-supplier  \n",
       "0                           NaN  \n",
       "1                      1.197368  \n",
       "2                      0.000000  \n",
       "3                      0.933333  \n",
       "4                      0.923077  \n",
       "\n",
       "[5 rows x 78 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "existing-suspect",
   "metadata": {},
   "outputs": [],
   "source": [
    "label = ['is_returned']\n",
    "\n",
    "categorical_str = [\n",
    "'is_saved_card_trx',\n",
    "'gender',\n",
    "'zodiac',\n",
    "'ANDROID',\n",
    "'ANDROID_qa-supplier',\n",
    "'IOS',\n",
    "'IOS_qa-supplier',\n",
    "'MOBILE_WEB',\n",
    "'MOBILE_WEB_qa-supplier',\n",
    "'WEB',\n",
    "'WEB_qa-supplier',\n",
    "'rate',\n",
    "'rate_reviews-supplier',\n",
    "] \n",
    "\n",
    "categorical_int = [\n",
    "'gender_id',\n",
    "'category_id',\n",
    "'color_id',\n",
    "'order_weekday',\n",
    "'order_week',\n",
    "'brand_id',\n",
    "'order_day',\n",
    "'hour_interval',\n",
    "]\n",
    "\n",
    "numerical = [\n",
    "'n_unq_variants',\n",
    "'original_price',\n",
    "'discounted_price',\n",
    "'ship_cost',\n",
    "'coupon_discount',\n",
    "'age',\n",
    "'diff_order_memdate',\n",
    "'total_claim',\n",
    "'promotion_award_value',\n",
    "'discount_ratio',\n",
    "'paid_amount',\n",
    "'beden_comment',\n",
    "'beden_comment_qa-supplier',\n",
    "'beden_question',\n",
    "'beden_question_qa-supplier',\n",
    "'kalite_comment',\n",
    "'kalite_comment_qa-supplier',\n",
    "'kalite_question',\n",
    "'kalite_question_qa-supplier',\n",
    "'neg_answers',\n",
    "'neg_answers_qa-supplier',\n",
    "'neg_comment',\n",
    "'neg_comment_reviews-supplier',\n",
    "'pos_answers',\n",
    "'pos_answers_qa-supplier',\n",
    "'pos_comment',\n",
    "'pos_comment_reviews-supplier',\n",
    "'review_like_count',\n",
    "'review_like_count_reviews-supplier'\n",
    "]\n",
    "\n",
    "numerical2 = [\n",
    "'returnRate',\n",
    "'returnRate_def',\n",
    "'unresolvedclaim_percentage',\n",
    "'unresolved_percentage',\n",
    "]\n",
    "passthrough = [\n",
    "'is_elite_user',\n",
    "'is_wallet_trx',\n",
    "'is_bday_close',\n",
    "\n",
    "]\n",
    "\n",
    "\n",
    "drops = [\n",
    "'color_name',\n",
    "'supplier_color_name',\n",
    "'attribute_value',\n",
    "'attributet_name',\n",
    "'gender_name',\n",
    "'category_name',\n",
    "'brand_name',\n",
    "'product_name',\n",
    "'coupon_id',\n",
    "'promotion_name',\n",
    "'order_date',\n",
    "'birth_date',\n",
    "'membership_date', \n",
    "'order_line_item_id',\n",
    "'order_parent_id',\n",
    "'product_content_id',\n",
    "'product_id',\n",
    "'product_variant_id',\n",
    "'supplier_id',\n",
    "'user_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "clinical-vacation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(df.columns).difference(set(categorical_str+categorical_int+numerical+numerical2+passthrough+label+drops))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ordinary-definition",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(categorical_str+categorical_int+numerical+numerical2+passthrough+label+drops).difference(set(df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "large-analyst",
   "metadata": {},
   "outputs": [],
   "source": [
    "null_df = df[df['is_returned'].isna()]\n",
    "notna_df = df[df['is_returned'].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "animal-hygiene",
   "metadata": {},
   "outputs": [],
   "source": [
    "del df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "portuguese-physics",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "approved-harvard",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(null_df['is_returned'].isna().sum()), print(notna_df['is_returned'].isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "collectible-wound",
   "metadata": {},
   "outputs": [],
   "source": [
    "null_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "approved-shopping",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(null_df['product_content_id'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "respective-shareware",
   "metadata": {},
   "outputs": [],
   "source": [
    "null_df.drop_duplicates(subset=['order_parent_id', 'product_content_id'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "powerful-sphere",
   "metadata": {},
   "outputs": [],
   "source": [
    "null_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "concrete-relay",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = notna_df[categorical_str+categorical_int+numerical+numerical2+passthrough+label]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "friendly-brain",
   "metadata": {},
   "source": [
    "matrix = merged_df.corr().abs()\n",
    "\n",
    "# Create a mask\n",
    "mask = np.triu(np.ones_like(matrix, dtype=bool))\n",
    "\n",
    "# Create a custom diverging palette\n",
    "cmap = sns.diverging_palette(250, 15, s=75, l=40, n=9, center=\"light\", as_cmap=True)\n",
    "plt.figure(figsize=(16, 12))\n",
    "sns.heatmap(matrix[matrix>0.5], mask=mask, center=0, annot=True, fmt='.2f', square=True, cmap='crest')\n",
    "\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "animated-weekly",
   "metadata": {},
   "source": [
    "veriyi alÄ±rken\n",
    "\n",
    "1. random\n",
    "2. time based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "auburn-function",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_df = merged_df[merged_df['is_returned']==1].sample(100000, random_state=1)\n",
    "neg_df = merged_df[merged_df['is_returned']==0].sample(100000, random_state=1)\n",
    "\n",
    "model_df = pd.concat([pos_df, neg_df], axis=0)\n",
    "model_df.sample(frac=1)\n",
    "\n",
    "y = model_df['is_returned']\n",
    "X = model_df[categorical_str+categorical_int+numerical+numerical2+passthrough]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "challenging-winning",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_metrics(y_pred, y_test, model):\n",
    "    print(\"Model results: \", type(model).__name__)\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(\"Confusion matrix:\")\n",
    "    cm = confusion_matrix(y_test,y_pred, labels= model.classes_)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm,display_labels= model.classes_)\n",
    "    disp.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "filled-denmark",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pipeline_rf():\n",
    "    \n",
    "    numeric_transformer = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='median')),\n",
    "        ('scaler', StandardScaler())])\n",
    "\n",
    "    numeric_transformer2 = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='mean'))])\n",
    "    \n",
    "    categorical_str_transformer = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "        ('one-hot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "    \n",
    "    categorical_int_transformer = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='constant', fill_value=-99)),\n",
    "        ('one-hot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "    \n",
    "\n",
    "    preprocessor = ColumnTransformer(\n",
    "                                    transformers=[\n",
    "                                                  ('num1', numeric_transformer, numerical),\n",
    "                                                  ('num2', numeric_transformer2, numerical2),\n",
    "                                                  ('cat_str1', categorical_str_transformer, categorical_str),\n",
    "                                                  ('cat_int1', categorical_int_transformer, categorical_int),\n",
    "                                                  ], \n",
    "                                    remainder='passthrough')\n",
    "\n",
    "    pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                          ('f_selector', SelectKBest(f_classif, k='all')),\n",
    "                          ('classifier', RandomForestClassifier(class_weight='balanced', n_jobs=-1, random_state=0))])\n",
    "    \n",
    "    return pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "funny-campaign",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.20, random_state=1)\n",
    "\n",
    "pipe1 = create_pipeline_rf()\n",
    "\n",
    "pipe1.fit(X_train, y_train)\n",
    "preds = pipe1.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "roman-highland",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_metrics(preds, y_test, pipe1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "coordinate-ecology",
   "metadata": {},
   "source": [
    "### feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "million-emphasis",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "#do code to support model\n",
    "#\"data\" is the X dataframe and model is the SKlearn object\n",
    "\n",
    "feats = {} # a dict to hold feature_name: feature_importance\n",
    "for feature, importance in zip(X.columns, pipe1['classifier'].feature_importances_):\n",
    "    feats[feature] = importance #add the name/value pair \n",
    "\n",
    "importances = pd.DataFrame.from_dict(feats, orient='index').rename(columns={0: 'importance'})\n",
    "importances.sort_values(by='importance').plot(kind='barh',figsize=(8,8))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "subject-graduation",
   "metadata": {},
   "source": [
    "## auto ml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "governmental-astrology",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model_with_CV(X, y, model):\n",
    "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=1)\n",
    "    scores = cross_validate(pipeline, X, y, scoring=['accuracy', 'f1_weighted'], n_jobs=-1, \n",
    "                        return_estimator=True, return_train_score=True, cv=cv)\n",
    "    # ['fit_time', 'score_time', 'estimator', 'test_accuracy', 'train_accuracy', 'test_f1_weighted', 'train_f1_weighted']\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "proprietary-morrison",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_metrics(y_pred, y_test, model):\n",
    "    print(\"Model results: \", type(model).__name__)\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(\"Confusion matrix:\")\n",
    "    cm = confusion_matrix(y_test,y_pred, labels= model.classes_)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm,display_labels= model.classes_)\n",
    "    disp.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sustainable-comedy",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pipeline_without_clf(clf_name, clf_object):\n",
    "    \n",
    "    numeric_transformer = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='median')),\n",
    "        ('scaler', StandardScaler())])\n",
    "\n",
    "    numeric_transformer2 = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='mean'))])\n",
    "    \n",
    "    categorical_str_transformer = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "        ('one-hot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "    \n",
    "    categorical_int_transformer = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='constant', fill_value=-99)),\n",
    "        ('one-hot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "    \n",
    "\n",
    "    preprocessor = ColumnTransformer(\n",
    "                                    transformers=[\n",
    "                                                  ('num1', numeric_transformer, numerical),\n",
    "                                                  ('num2', numeric_transformer2, numerical2),\n",
    "                                                  ('cat_str1', categorical_str_transformer, categorical_str),\n",
    "                                                  ('cat_int1', categorical_int_transformer, categorical_int),\n",
    "                                                  ], \n",
    "                                    remainder='passthrough')\n",
    "\n",
    "    pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                          ('f_selector', SelectKBest(f_classif, k='all')),\n",
    "                          (clf_name, clf_object)], verbose=False)\n",
    "    \n",
    "    return pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "subject-tracker",
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASSIFIERS = [\n",
    " ('AdaBoostClassifier', sklearn.ensemble._weight_boosting.AdaBoostClassifier),\n",
    " ('KNeighborsClassifier', sklearn.neighbors._classification.KNeighborsClassifier),\n",
    " ('LogisticRegression', sklearn.linear_model._logistic.LogisticRegression),\n",
    " ('XGBClassifier', XGBClassifier),\n",
    " ('LGBMClassifier', LGBMClassifier)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "national-valve",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = 10\n",
    "Accuracy_mean = []\n",
    "Accuracy_std = []\n",
    "F1_mean = []\n",
    "F1_std = []\n",
    "names = []\n",
    "TIME = []\n",
    "predictions = {}\n",
    "models = {}\n",
    "\n",
    "for name, model in tqdm(CLASSIFIERS):\n",
    "    start = time.time()\n",
    "    try:\n",
    "        if \"random_state\" in model().get_params().keys():\n",
    "            if \"class_weight\" in model().get_params().keys():\n",
    "                pipeline = create_pipeline_without_clf(\"classifier\", model(random_state=random_state, class_weight='balanced'))\n",
    "            else:\n",
    "                pipeline = create_pipeline_without_clf(\"classifier\", model(random_state=random_state))\n",
    "        else:\n",
    "            if \"class_weight\" in model().get_params().keys():\n",
    "                pipeline = create_pipeline_without_clf(\"classifier\", model(class_weight='balanced'))\n",
    "            else:\n",
    "                pipeline = create_pipeline_without_clf(\"classifier\", model())\n",
    "                \n",
    "                                   \n",
    "        results = evaluate_model_with_CV(X, y, model)\n",
    "                        \n",
    "        names.append(name)\n",
    "        Accuracy_mean.append(results['test_accuracy'].mean())\n",
    "        Accuracy_std.append(results['test_accuracy'].std())\n",
    "        F1_mean.append(results['test_f1_weighted'].mean())\n",
    "        F1_std.append(results['test_f1_weighted'].std())\n",
    "        TIME.append(results['fit_time'].mean())\n",
    "    \n",
    "    except Exception as exception:\n",
    "        print(name + \" model failed to execute\")\n",
    "        print(exception)\n",
    "                                   \n",
    "scores = pd.DataFrame(\n",
    "    {   \"Model\": names,\n",
    "        \"Accuracy Mean\": Accuracy_mean,\n",
    "        \"Accuracy Std\": Accuracy_std,\n",
    "        \"F1-Score Mean\": F1_mean,\n",
    "        \"F1-Score Std\": F1_std,\n",
    "        \"Time Taken\": TIME, })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "southern-scenario",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores.sort_values(by='F1-Score Mean', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "divided-allah",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_df = merged_df[merged_df['is_returned']==1].sample(50000, random_state=1)\n",
    "neg_df = merged_df[merged_df['is_returned']==0].sample(50000, random_state=1)\n",
    "\n",
    "model_df = pd.concat([pos_df, neg_df], axis=0)\n",
    "model_df.sample(frac=1)\n",
    "\n",
    "y = model_df['is_returned']\n",
    "X = model_df[categorical_str+categorical_int+numerical+numerical2+passthrough]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "respective-product",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = 10\n",
    "Accuracy_mean = []\n",
    "Accuracy_std = []\n",
    "F1_mean = []\n",
    "F1_std = []\n",
    "names = []\n",
    "TIME = []\n",
    "predictions = {}\n",
    "models = {}\n",
    "\n",
    "for name, model in tqdm(CLASSIFIERS):\n",
    "    start = time.time()\n",
    "    try:\n",
    "        if \"random_state\" in model().get_params().keys():\n",
    "            if \"class_weight\" in model().get_params().keys():\n",
    "                pipeline = create_pipeline_without_clf(\"classifier\", model(random_state=random_state, class_weight='balanced'))\n",
    "            else:\n",
    "                pipeline = create_pipeline_without_clf(\"classifier\", model(random_state=random_state))\n",
    "        else:\n",
    "            if \"class_weight\" in model().get_params().keys():\n",
    "                pipeline = create_pipeline_without_clf(\"classifier\", model(class_weight='balanced'))\n",
    "            else:\n",
    "                pipeline = create_pipeline_without_clf(\"classifier\", model())\n",
    "                \n",
    "                                   \n",
    "        results = evaluate_model_with_CV(X, y, model)\n",
    "                        \n",
    "        names.append(name)\n",
    "        Accuracy_mean.append(results['test_accuracy'].mean())\n",
    "        Accuracy_std.append(results['test_accuracy'].std())\n",
    "        F1_mean.append(results['test_f1_weighted'].mean())\n",
    "        F1_std.append(results['test_f1_weighted'].std())\n",
    "        TIME.append(results['fit_time'].mean())\n",
    "    \n",
    "    except Exception as exception:\n",
    "        print(name + \" model failed to execute\")\n",
    "        print(exception)\n",
    "                                   \n",
    "scores2 = pd.DataFrame(\n",
    "    {   \"Model\": names,\n",
    "        \"Accuracy Mean\": Accuracy_mean,\n",
    "        \"Accuracy Std\": Accuracy_std,\n",
    "        \"F1-Score Mean\": F1_mean,\n",
    "        \"F1-Score Std\": F1_std,\n",
    "        \"Time Taken\": TIME, })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "starting-wales",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores2.sort_values(by='F1-Score Mean', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "emotional-israel",
   "metadata": {},
   "outputs": [],
   "source": [
    "XGBClassifier\n",
    "LGBMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lonely-sigma",
   "metadata": {},
   "outputs": [],
   "source": [
    "different encodings\n",
    "    category_name'i encoding? one-hot\n",
    "    \n",
    "    encodings:\n",
    "    \n",
    "    Frequency Encoding\n",
    "\n",
    "    Replace the values with its frequency\n",
    "    But be careful, some values may have same frequency\n",
    "    data[â€˜countryâ€™].value_counts()\n",
    "\n",
    "    Target Encoding (Mean encoding)\n",
    "\n",
    "    Each of the categories is the variable is replaced with the mean target value for that category\n",
    "    for each catergory in a column: sum of target / count of target "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lovely-shopping",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "macro-strip",
   "metadata": {},
   "source": [
    "## validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "advanced-platform",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = r'C:\\Users\\IsmailKaraman\\workspace\\data\\trendyol\\\\'\n",
    "test_raw = pd.read_csv(data_path+'test_data.csv')\n",
    "test_raw.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "educational-resistance",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test_raw.copy()\n",
    "test[['user_id', 'product_content_id', 'order_parent_id']] = test['id'].str.split('|',expand=True)\n",
    "test = test[['user_id', 'product_content_id', 'order_parent_id','expected']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hairy-railway",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "outside-advice",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "western-waters",
   "metadata": {},
   "outputs": [],
   "source": [
    "test['user_id'] = test['user_id'].astype('int64') \n",
    "test['order_parent_id'] = test['order_parent_id'].astype('int64')\n",
    "test['product_content_id'] = test['product_content_id'].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "constant-malawi",
   "metadata": {},
   "outputs": [],
   "source": [
    "null_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incorporate-noise",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.merge(test, null_df, on=['user_id', 'product_content_id', 'order_parent_id'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "meaningful-token",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "southern-bathroom",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "three-louisiana",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "harmful-placement",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_X = test_df[categorical_str+categorical_int+numerical+numerical2+passthrough]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "behavioral-clock",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_X.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mysterious-stanford",
   "metadata": {},
   "outputs": [],
   "source": [
    "expected = pipe1.predict(test_df[categorical_str+categorical_int+numerical+numerical2+passthrough])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sophisticated-billy",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_raw['expected'] = expected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bridal-portland",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_raw['expected'] = test_raw['expected'].astype('int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "green-runner",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_raw.to_csv('output.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "color-colors",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
