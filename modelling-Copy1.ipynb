{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "applicable-venture",
   "metadata": {},
   "source": [
    "different encodings\n",
    "    category_name'i encoding? one-hot\n",
    "    \n",
    "    encodings:\n",
    "    \n",
    "    Frequency Encoding\n",
    "\n",
    "    Replace the values with its frequency\n",
    "    But be careful, some values may have same frequency\n",
    "    data[‘country’].value_counts()\n",
    "\n",
    "    Target Encoding (Mean encoding)\n",
    "\n",
    "    Each of the categories is the variable is replaced with the mean target value for that category\n",
    "    for each catergory in a column: sum of target / count of target "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "graduate-hands",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import missingno as msgn\n",
    "import time\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from pandas_profiling import ProfileReport\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.feature_selection import f_classif\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.metrics import *\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, PowerTransformer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_validate, StratifiedKFold, train_test_split, cross_val_score\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.feature_selection import SelectKBest, mutual_info_classif, f_classif\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix, ConfusionMatrixDisplay, f1_score\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import VotingClassifier, StackingClassifier\n",
    "\n",
    "import sklearn\n",
    "from tqdm import tqdm\n",
    "from sklearn.base import ClassifierMixin\n",
    "from sklearn.utils.testing import all_estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "antique-prescription",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle('df_v2.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "lined-generator",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_date</th>\n",
       "      <th>user_id</th>\n",
       "      <th>is_elite_user</th>\n",
       "      <th>supplier_id</th>\n",
       "      <th>order_line_item_id</th>\n",
       "      <th>order_parent_id</th>\n",
       "      <th>product_variant_id</th>\n",
       "      <th>original_price</th>\n",
       "      <th>discounted_price</th>\n",
       "      <th>ship_cost</th>\n",
       "      <th>...</th>\n",
       "      <th>cum_prod_counts</th>\n",
       "      <th>cum_cat_counts_x</th>\n",
       "      <th>cum_cat_counts_y</th>\n",
       "      <th>past_total_paid</th>\n",
       "      <th>past_avg_paid</th>\n",
       "      <th>ship_cost_ratio</th>\n",
       "      <th>past_avg_prod_price</th>\n",
       "      <th>past_coupon_usage_rate</th>\n",
       "      <th>prod_past_avg_ratio</th>\n",
       "      <th>paid_cart_amount_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-05-19 01:27:28.768000+00:00</td>\n",
       "      <td>2141</td>\n",
       "      <td>0</td>\n",
       "      <td>216503</td>\n",
       "      <td>955598029</td>\n",
       "      <td>625610651</td>\n",
       "      <td>133066437</td>\n",
       "      <td>104.900002</td>\n",
       "      <td>69.900002</td>\n",
       "      <td>11.33</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.139480</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>inf</td>\n",
       "      <td>0.955085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-05-19 01:27:28.768000+00:00</td>\n",
       "      <td>2141</td>\n",
       "      <td>0</td>\n",
       "      <td>1188</td>\n",
       "      <td>955598030</td>\n",
       "      <td>625610651</td>\n",
       "      <td>77047570</td>\n",
       "      <td>79.989998</td>\n",
       "      <td>79.989998</td>\n",
       "      <td>8.88</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.099921</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>inf</td>\n",
       "      <td>1.044915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-06-02 00:51:35.862000+00:00</td>\n",
       "      <td>2141</td>\n",
       "      <td>0</td>\n",
       "      <td>200788</td>\n",
       "      <td>988146564</td>\n",
       "      <td>643936439</td>\n",
       "      <td>153411316</td>\n",
       "      <td>110.300003</td>\n",
       "      <td>55.150002</td>\n",
       "      <td>8.88</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>170.100006</td>\n",
       "      <td>170.100006</td>\n",
       "      <td>0.138685</td>\n",
       "      <td>85.050003</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.752851</td>\n",
       "      <td>1.042749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-06-02 00:51:35.862000+00:00</td>\n",
       "      <td>2141</td>\n",
       "      <td>0</td>\n",
       "      <td>107296</td>\n",
       "      <td>988146563</td>\n",
       "      <td>643936439</td>\n",
       "      <td>172744639</td>\n",
       "      <td>59.900002</td>\n",
       "      <td>49.900002</td>\n",
       "      <td>8.88</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>170.100006</td>\n",
       "      <td>170.100006</td>\n",
       "      <td>0.151072</td>\n",
       "      <td>85.050003</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.691123</td>\n",
       "      <td>0.957251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-06-09 23:31:37.963000+00:00</td>\n",
       "      <td>2141</td>\n",
       "      <td>0</td>\n",
       "      <td>968</td>\n",
       "      <td>1007223734</td>\n",
       "      <td>654756664</td>\n",
       "      <td>162306389</td>\n",
       "      <td>119.989998</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>9.40</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>292.910004</td>\n",
       "      <td>146.455002</td>\n",
       "      <td>0.145827</td>\n",
       "      <td>61.404999</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.049752</td>\n",
       "      <td>1.331818</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 84 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        order_date  user_id  is_elite_user  supplier_id  \\\n",
       "0 2021-05-19 01:27:28.768000+00:00     2141              0       216503   \n",
       "1 2021-05-19 01:27:28.768000+00:00     2141              0         1188   \n",
       "2 2021-06-02 00:51:35.862000+00:00     2141              0       200788   \n",
       "3 2021-06-02 00:51:35.862000+00:00     2141              0       107296   \n",
       "4 2021-06-09 23:31:37.963000+00:00     2141              0          968   \n",
       "\n",
       "   order_line_item_id  order_parent_id  product_variant_id  original_price  \\\n",
       "0           955598029        625610651           133066437      104.900002   \n",
       "1           955598030        625610651            77047570       79.989998   \n",
       "2           988146564        643936439           153411316      110.300003   \n",
       "3           988146563        643936439           172744639       59.900002   \n",
       "4          1007223734        654756664           162306389      119.989998   \n",
       "\n",
       "   discounted_price  ship_cost  ... cum_prod_counts  cum_cat_counts_x  \\\n",
       "0         69.900002      11.33  ...             0.0               0.0   \n",
       "1         79.989998       8.88  ...             0.0               0.0   \n",
       "2         55.150002       8.88  ...             0.0               0.0   \n",
       "3         49.900002       8.88  ...             0.0               0.0   \n",
       "4         48.000000       9.40  ...             0.0               0.0   \n",
       "\n",
       "  cum_cat_counts_y  past_total_paid past_avg_paid ship_cost_ratio  \\\n",
       "0              0.0         0.000000      0.000000        0.139480   \n",
       "1              0.0         0.000000      0.000000        0.099921   \n",
       "2              0.0       170.100006    170.100006        0.138685   \n",
       "3              0.0       170.100006    170.100006        0.151072   \n",
       "4              0.0       292.910004    146.455002        0.145827   \n",
       "\n",
       "   past_avg_prod_price  past_coupon_usage_rate prod_past_avg_ratio  \\\n",
       "0             0.000000                     0.0                 inf   \n",
       "1             0.000000                     0.0                 inf   \n",
       "2            85.050003                     0.0            0.752851   \n",
       "3            85.050003                     0.0            0.691123   \n",
       "4            61.404999                     0.0            1.049752   \n",
       "\n",
       "   paid_cart_amount_ratio  \n",
       "0                0.955085  \n",
       "1                1.044915  \n",
       "2                1.042749  \n",
       "3                0.957251  \n",
       "4                1.331818  \n",
       "\n",
       "[5 rows x 84 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "unauthorized-lithuania",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>is_elite_user</th>\n",
       "      <th>supplier_id</th>\n",
       "      <th>order_line_item_id</th>\n",
       "      <th>order_parent_id</th>\n",
       "      <th>product_variant_id</th>\n",
       "      <th>original_price</th>\n",
       "      <th>discounted_price</th>\n",
       "      <th>ship_cost</th>\n",
       "      <th>coupon_discount</th>\n",
       "      <th>...</th>\n",
       "      <th>cum_prod_counts</th>\n",
       "      <th>cum_cat_counts_x</th>\n",
       "      <th>cum_cat_counts_y</th>\n",
       "      <th>past_total_paid</th>\n",
       "      <th>past_avg_paid</th>\n",
       "      <th>ship_cost_ratio</th>\n",
       "      <th>past_avg_prod_price</th>\n",
       "      <th>past_coupon_usage_rate</th>\n",
       "      <th>prod_past_avg_ratio</th>\n",
       "      <th>paid_cart_amount_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.119368e+07</td>\n",
       "      <td>1.119368e+07</td>\n",
       "      <td>1.119368e+07</td>\n",
       "      <td>1.119368e+07</td>\n",
       "      <td>1.119368e+07</td>\n",
       "      <td>1.119368e+07</td>\n",
       "      <td>1.119368e+07</td>\n",
       "      <td>1.119368e+07</td>\n",
       "      <td>1.119368e+07</td>\n",
       "      <td>1.119368e+07</td>\n",
       "      <td>...</td>\n",
       "      <td>11193677.0</td>\n",
       "      <td>11193677.0</td>\n",
       "      <td>11193677.0</td>\n",
       "      <td>1.119368e+07</td>\n",
       "      <td>1.119368e+07</td>\n",
       "      <td>1.119368e+07</td>\n",
       "      <td>1.119368e+07</td>\n",
       "      <td>1.119368e+07</td>\n",
       "      <td>1.119368e+07</td>\n",
       "      <td>1.119368e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.158935e+07</td>\n",
       "      <td>3.213201e-01</td>\n",
       "      <td>6.534671e+04</td>\n",
       "      <td>1.008799e+09</td>\n",
       "      <td>6.590039e+08</td>\n",
       "      <td>1.211778e+08</td>\n",
       "      <td>1.002923e+02</td>\n",
       "      <td>6.701447e+01</td>\n",
       "      <td>5.588512e+00</td>\n",
       "      <td>-9.380584e-01</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.838929e+04</td>\n",
       "      <td>1.807843e+02</td>\n",
       "      <td>9.956559e-02</td>\n",
       "      <td>6.873257e+01</td>\n",
       "      <td>5.303776e-02</td>\n",
       "      <td>inf</td>\n",
       "      <td>1.006822e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.631568e+07</td>\n",
       "      <td>4.669834e-01</td>\n",
       "      <td>1.032800e+05</td>\n",
       "      <td>6.203067e+07</td>\n",
       "      <td>3.880737e+07</td>\n",
       "      <td>4.827560e+07</td>\n",
       "      <td>1.007572e+02</td>\n",
       "      <td>6.450294e+01</td>\n",
       "      <td>3.425355e+00</td>\n",
       "      <td>6.268884e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.566596e+05</td>\n",
       "      <td>2.358173e+02</td>\n",
       "      <td>7.337081e-02</td>\n",
       "      <td>7.500220e+01</td>\n",
       "      <td>1.529944e-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.126727e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2.141000e+03</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>6.200000e+01</td>\n",
       "      <td>9.006235e+08</td>\n",
       "      <td>5.957590e+08</td>\n",
       "      <td>1.010649e+06</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>-5.990000e+02</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2.767197e-03</td>\n",
       "      <td>5.299730e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.075593e+07</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>9.680000e+02</td>\n",
       "      <td>9.539981e+08</td>\n",
       "      <td>6.246996e+08</td>\n",
       "      <td>7.466463e+07</td>\n",
       "      <td>4.999000e+01</td>\n",
       "      <td>3.499000e+01</td>\n",
       "      <td>2.960000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.022600e+02</td>\n",
       "      <td>7.638000e+01</td>\n",
       "      <td>4.668720e-02</td>\n",
       "      <td>3.106471e+01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>6.308842e-01</td>\n",
       "      <td>8.392289e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.648916e+07</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>9.680000e+02</td>\n",
       "      <td>1.009282e+09</td>\n",
       "      <td>6.558869e+08</td>\n",
       "      <td>1.374928e+08</td>\n",
       "      <td>6.999000e+01</td>\n",
       "      <td>5.099000e+01</td>\n",
       "      <td>4.700000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.687700e+02</td>\n",
       "      <td>1.421050e+02</td>\n",
       "      <td>8.163265e-02</td>\n",
       "      <td>5.869250e+01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.090093e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.942272e+07</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.109690e+05</td>\n",
       "      <td>1.061361e+09</td>\n",
       "      <td>6.945076e+08</td>\n",
       "      <td>1.588897e+08</td>\n",
       "      <td>1.199900e+02</td>\n",
       "      <td>7.999000e+01</td>\n",
       "      <td>9.400000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.788350e+03</td>\n",
       "      <td>2.164217e+02</td>\n",
       "      <td>1.328546e-01</td>\n",
       "      <td>8.887000e+01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2.849844e+00</td>\n",
       "      <td>1.093331e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>7.117321e+07</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>4.349940e+05</td>\n",
       "      <td>1.149210e+09</td>\n",
       "      <td>7.299664e+08</td>\n",
       "      <td>2.243728e+08</td>\n",
       "      <td>1.222000e+04</td>\n",
       "      <td>6.950000e+03</td>\n",
       "      <td>1.320000e+01</td>\n",
       "      <td>2.000000e-02</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.991529e+07</td>\n",
       "      <td>1.425140e+04</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>6.963200e+03</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>inf</td>\n",
       "      <td>2.009621e+01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 62 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            user_id  is_elite_user   supplier_id  order_line_item_id  \\\n",
       "count  1.119368e+07   1.119368e+07  1.119368e+07        1.119368e+07   \n",
       "mean   2.158935e+07   3.213201e-01  6.534671e+04        1.008799e+09   \n",
       "std    1.631568e+07   4.669834e-01  1.032800e+05        6.203067e+07   \n",
       "min    2.141000e+03   0.000000e+00  6.200000e+01        9.006235e+08   \n",
       "25%    1.075593e+07   0.000000e+00  9.680000e+02        9.539981e+08   \n",
       "50%    1.648916e+07   0.000000e+00  9.680000e+02        1.009282e+09   \n",
       "75%    2.942272e+07   1.000000e+00  1.109690e+05        1.061361e+09   \n",
       "max    7.117321e+07   1.000000e+00  4.349940e+05        1.149210e+09   \n",
       "\n",
       "       order_parent_id  product_variant_id  original_price  discounted_price  \\\n",
       "count     1.119368e+07        1.119368e+07    1.119368e+07      1.119368e+07   \n",
       "mean      6.590039e+08        1.211778e+08    1.002923e+02      6.701447e+01   \n",
       "std       3.880737e+07        4.827560e+07    1.007572e+02      6.450294e+01   \n",
       "min       5.957590e+08        1.010649e+06    0.000000e+00      0.000000e+00   \n",
       "25%       6.246996e+08        7.466463e+07    4.999000e+01      3.499000e+01   \n",
       "50%       6.558869e+08        1.374928e+08    6.999000e+01      5.099000e+01   \n",
       "75%       6.945076e+08        1.588897e+08    1.199900e+02      7.999000e+01   \n",
       "max       7.299664e+08        2.243728e+08    1.222000e+04      6.950000e+03   \n",
       "\n",
       "          ship_cost  coupon_discount  ...  cum_prod_counts  cum_cat_counts_x  \\\n",
       "count  1.119368e+07     1.119368e+07  ...       11193677.0        11193677.0   \n",
       "mean   5.588512e+00    -9.380584e-01  ...              0.0               0.0   \n",
       "std    3.425355e+00     6.268884e+00  ...              0.0               0.0   \n",
       "min    0.000000e+00    -5.990000e+02  ...              0.0               0.0   \n",
       "25%    2.960000e+00     0.000000e+00  ...              0.0               0.0   \n",
       "50%    4.700000e+00     0.000000e+00  ...              0.0               0.0   \n",
       "75%    9.400000e+00     0.000000e+00  ...              0.0               0.0   \n",
       "max    1.320000e+01     2.000000e-02  ...              0.0               0.0   \n",
       "\n",
       "       cum_cat_counts_y  past_total_paid  past_avg_paid  ship_cost_ratio  \\\n",
       "count        11193677.0     1.119368e+07   1.119368e+07     1.119368e+07   \n",
       "mean                0.0     3.838929e+04   1.807843e+02     9.956559e-02   \n",
       "std                 0.0     6.566596e+05   2.358173e+02     7.337081e-02   \n",
       "min                 0.0     0.000000e+00   0.000000e+00     0.000000e+00   \n",
       "25%                 0.0     1.022600e+02   7.638000e+01     4.668720e-02   \n",
       "50%                 0.0     5.687700e+02   1.421050e+02     8.163265e-02   \n",
       "75%                 0.0     1.788350e+03   2.164217e+02     1.328546e-01   \n",
       "max                 0.0     1.991529e+07   1.425140e+04     1.000000e+00   \n",
       "\n",
       "       past_avg_prod_price  past_coupon_usage_rate  prod_past_avg_ratio  \\\n",
       "count         1.119368e+07            1.119368e+07         1.119368e+07   \n",
       "mean          6.873257e+01            5.303776e-02                  inf   \n",
       "std           7.500220e+01            1.529944e-01                  NaN   \n",
       "min           0.000000e+00            0.000000e+00         2.767197e-03   \n",
       "25%           3.106471e+01            0.000000e+00         6.308842e-01   \n",
       "50%           5.869250e+01            0.000000e+00         1.090093e+00   \n",
       "75%           8.887000e+01            0.000000e+00         2.849844e+00   \n",
       "max           6.963200e+03            1.000000e+00                  inf   \n",
       "\n",
       "       paid_cart_amount_ratio  \n",
       "count            1.119368e+07  \n",
       "mean             1.006822e+00  \n",
       "std              3.126727e-01  \n",
       "min              5.299730e-03  \n",
       "25%              8.392289e-01  \n",
       "50%              1.000000e+00  \n",
       "75%              1.093331e+00  \n",
       "max              2.009621e+01  \n",
       "\n",
       "[8 rows x 62 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "early-flash",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "order_date                           0\n",
       "user_id                              0\n",
       "is_elite_user                        0\n",
       "supplier_id                          0\n",
       "order_line_item_id                   0\n",
       "order_parent_id                      0\n",
       "product_variant_id                   0\n",
       "original_price                       0\n",
       "discounted_price                     0\n",
       "ship_cost                            0\n",
       "coupon_id                     10433735\n",
       "coupon_discount                      0\n",
       "promotion_name                 5653910\n",
       "promotion_award_value                0\n",
       "is_wallet_trx                        0\n",
       "is_saved_card_trx                    0\n",
       "is_returned                     421016\n",
       "product_id                           0\n",
       "product_name                         0\n",
       "brand_id                             0\n",
       "brand_name                           0\n",
       "gender_id                         7223\n",
       "gender_name                          0\n",
       "category_id                          0\n",
       "category_name                        0\n",
       "color_id                          5217\n",
       "color_name                        5217\n",
       "supplier_color_name                  1\n",
       "attributet_name                      0\n",
       "attribute_value                      0\n",
       "n_unq_variants                       0\n",
       "birth_date                           0\n",
       "membership_date                      0\n",
       "gender                               0\n",
       "returnRate                          37\n",
       "returnRate_def                      37\n",
       "total_claim                       3215\n",
       "unresolvedclaim_percentage        3215\n",
       "unresolved_percentage             3215\n",
       "product_content_id                   0\n",
       "paid_amount                          0\n",
       "discount_ratio                       2\n",
       "hour_interval                        0\n",
       "diff_order_memdate                   0\n",
       "order_weekday                        0\n",
       "order_day                            0\n",
       "order_week                           0\n",
       "zodiac                               0\n",
       "age                                  0\n",
       "is_bday_close                        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum().head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "existing-suspect",
   "metadata": {},
   "outputs": [],
   "source": [
    "label = ['is_returned']\n",
    "\n",
    "drop_nulls_list = ['gender_id',\n",
    "'color_id',\n",
    "'returnRate',\n",
    "'returnRate_def',\n",
    "'total_claim',\n",
    "'unresolvedclaim_percentage',\n",
    "'unresolved_percentage',\n",
    "'discount_ratio',\n",
    "'rate',\n",
    "'review_like_count',\n",
    "'pos_comment',\n",
    "'neg_comment',]\n",
    "\n",
    "categorical_str = [\n",
    "'is_saved_card_trx',\n",
    "'gender',\n",
    "'zodiac',\n",
    "'rate',\n",
    "] \n",
    "\n",
    "\n",
    "colls_have_null = ['ANDROID'  ,  \n",
    "'IOS'   ,           \n",
    "'MOBILE_WEB'   ,             \n",
    "'WEB'   ,                   \n",
    "'pos_answers' ,\n",
    "'neg_answers',\n",
    "'beden_comment'  ,\n",
    "'beden_question' ,\n",
    "'kalite_comment' ,\n",
    "'kalite_question',]\n",
    "\n",
    "categorical_int = [\n",
    "'gender_id',\n",
    "'category_id',\n",
    "'color_id',\n",
    "'order_weekday',\n",
    "'order_week',\n",
    "'brand_id',\n",
    "'order_day',\n",
    "'hour_interval',\n",
    "]\n",
    "\n",
    "numerical = [\n",
    "'n_unq_variants',\n",
    "'original_price',\n",
    "'discounted_price',\n",
    "'ship_cost',\n",
    "'coupon_discount',\n",
    "'age',\n",
    "'diff_order_memdate',\n",
    "'total_claim',\n",
    "'promotion_award_value',\n",
    "'discount_ratio',\n",
    "'paid_amount',\n",
    "'neg_comment',\n",
    "'pos_comment',\n",
    "'review_like_count',]\n",
    "\n",
    "\n",
    "numerical2 = [\n",
    "'returnRate',\n",
    "'returnRate_def',\n",
    "'unresolvedclaim_percentage',\n",
    "'unresolved_percentage',\n",
    "]\n",
    "passthrough = [\n",
    "'is_elite_user',\n",
    "'is_wallet_trx',\n",
    "'is_bday_close',\n",
    "'user_id']\n",
    "\n",
    "\n",
    "drops = [\n",
    "'color_name',\n",
    "'supplier_color_name',\n",
    "'attribute_value',\n",
    "'attributet_name',\n",
    "'gender_name',\n",
    "'category_name',\n",
    "'brand_name',\n",
    "'product_name',\n",
    "'coupon_id',\n",
    "'promotion_name',\n",
    "'order_date',\n",
    "'birth_date',\n",
    "'membership_date', \n",
    "'order_line_item_id',\n",
    "'order_parent_id',\n",
    "'product_content_id',\n",
    "'product_id',\n",
    "'product_variant_id',\n",
    "'supplier_id',\n",
    "'user_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "clinical-vacation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ANDROID',\n",
       " 'IOS',\n",
       " 'MOBILE_WEB',\n",
       " 'WEB',\n",
       " 'beden_comment',\n",
       " 'beden_question',\n",
       " 'cart_amount_mean',\n",
       " 'cat_cum_mean',\n",
       " 'cum_cat_counts_x',\n",
       " 'cum_cat_counts_y',\n",
       " 'cum_prod_counts',\n",
       " 'general_prod_return_rate',\n",
       " 'item_return_rate_user',\n",
       " 'kalite_comment',\n",
       " 'kalite_question',\n",
       " 'n_unique_cats_in_basket',\n",
       " 'n_unique_prods_in_basket',\n",
       " 'neg_answers',\n",
       " 'paid_cart_amount_ratio',\n",
       " 'past_avg_paid',\n",
       " 'past_avg_prod_price',\n",
       " 'past_coupon_usage_rate',\n",
       " 'past_total_paid',\n",
       " 'pos_answers',\n",
       " 'prod_cum_mean',\n",
       " 'prod_past_avg_ratio',\n",
       " 'shifted_cum_mean_x',\n",
       " 'shifted_cum_mean_y',\n",
       " 'shifted_return_rate',\n",
       " 'ship_cost_ratio'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(df.columns).difference(set(categorical_str+categorical_int+numerical+numerical2+passthrough+label+drops))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ordinary-definition",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(categorical_str+categorical_int+numerical+numerical2+passthrough+label+drops).difference(set(df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "large-analyst",
   "metadata": {},
   "outputs": [],
   "source": [
    "null_df = df[df['is_returned'].isna()]\n",
    "notna_df = df[df['is_returned'].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "internal-territory",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-10-810bc6c38535>:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  notna_df.dropna(subset=drop_nulls_list, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "notna_df.dropna(subset=drop_nulls_list, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "swiss-responsibility",
   "metadata": {},
   "source": [
    "# conflicts\n",
    "data_tra.dropna(subset=['is_returned'], inplace=True)\n",
    "data_tra['key'] = data_tra['user_id'].astype(str) + '-' + data_tra['product_content_id'].astype(str)\n",
    "conflicts_indexes = set(data_tra.drop_duplicates(subset=['user_id', 'product_content_id','is_returned']).index).difference(set(data_tra.drop_duplicates(subset=['user_id', 'product_content_id']).index))\n",
    "print('len of conflicts', len(conflicts_indexes))\n",
    "all_conflict_indexes = data_tra[data_tra['key'].isin(data_tra.loc[conflicts_indexes]['key'])].index\n",
    "print('len of all conflicts', len(all_conflict_indexes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "checked-netherlands",
   "metadata": {},
   "outputs": [],
   "source": [
    "del df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "portuguese-physics",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "important-possible",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(421016, 84)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "null_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "respective-shareware",
   "metadata": {},
   "outputs": [],
   "source": [
    "null_df.drop_duplicates(subset=['order_parent_id', 'product_content_id'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "powerful-sphere",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(405282, 84)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "null_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "precise-labor",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10424398, 84)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "notna_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "romance-fantasy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "order_date                0\n",
       "user_id                   0\n",
       "is_elite_user             0\n",
       "supplier_id               0\n",
       "order_line_item_id        0\n",
       "                         ..\n",
       "ship_cost_ratio           0\n",
       "past_avg_prod_price       0\n",
       "past_coupon_usage_rate    0\n",
       "prod_past_avg_ratio       0\n",
       "paid_cart_amount_ratio    0\n",
       "Length: 84, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "notna_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "prompt-executive",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6424398, 84)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_train = notna_df.sort_values('order_parent_id')[4_000_000:]\n",
    "sorted_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "concrete-relay",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = sorted_train[categorical_str+categorical_int+numerical+numerical2+passthrough+label]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "friendly-brain",
   "metadata": {},
   "source": [
    "matrix = merged_df.corr().abs()\n",
    "\n",
    "# Create a mask\n",
    "mask = np.triu(np.ones_like(matrix, dtype=bool))\n",
    "\n",
    "# Create a custom diverging palette\n",
    "cmap = sns.diverging_palette(250, 15, s=75, l=40, n=9, center=\"light\", as_cmap=True)\n",
    "plt.figure(figsize=(16, 12))\n",
    "sns.heatmap(matrix[matrix>0.5], mask=mask, center=0, annot=True, fmt='.2f', square=True, cmap='crest')\n",
    "\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "animated-weekly",
   "metadata": {},
   "source": [
    "veriyi alırken\n",
    "\n",
    "1. random\n",
    "2. time based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "auburn-function",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_df = merged_df[merged_df['is_returned']==1].sample(200_000, random_state=0)\n",
    "neg_df = merged_df[merged_df['is_returned']==0].sample(200_000, random_state=0)\n",
    "\n",
    "model_df = pd.concat([pos_df, neg_df], axis=0)\n",
    "model_df.sample(frac=1)\n",
    "\n",
    "y = model_df['is_returned']\n",
    "X = model_df[categorical_str+categorical_int+numerical+numerical2+passthrough]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "challenging-winning",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_metrics(y_pred, y_test, model):\n",
    "    print(\"Model results: \", type(model).__name__)\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(\"Confusion matrix:\")\n",
    "    cm = confusion_matrix(y_test,y_pred, labels= model.classes_)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm,display_labels= model.classes_)\n",
    "    disp.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "filled-denmark",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pipeline(clf_name, clf_object):\n",
    "    \n",
    "    numeric_transformer = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='median')),\n",
    "        ('scaler', StandardScaler())])\n",
    "\n",
    "    numeric_transformer2 = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='mean'))])\n",
    "    \n",
    "    categorical_str_transformer = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "        ('one-hot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "    \n",
    "    categorical_int_transformer = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='constant', fill_value=-99)),\n",
    "        ('one-hot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "    \n",
    "\n",
    "    preprocessor = ColumnTransformer(\n",
    "                                    transformers=[\n",
    "                                                  ('num1', numeric_transformer, numerical),\n",
    "                                                  ('num2', numeric_transformer2, numerical2),\n",
    "                                                  ('cat_str1', categorical_str_transformer, categorical_str),\n",
    "                                                  ('cat_int1', categorical_int_transformer, categorical_int),\n",
    "                                                  ], \n",
    "                                    remainder='passthrough')\n",
    "\n",
    "    pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                          ('f_selector', SelectKBest(f_classif, k=30)),\n",
    "                          (clf_name, clf_object)])\n",
    "    \n",
    "    return pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "technological-collar",
   "metadata": {},
   "source": [
    "from category_encoders import TargetEncoder\n",
    "encoder = TargetEncoder(cols='user_id')\n",
    "X_train['user_id'] = encoder.fit_transform(X_train['user_id'], y_train)\n",
    "X_test['user_id'] = encoder.transform(X_test['user_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "funny-campaign",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.20, random_state=1)\n",
    "\n",
    "\n",
    "pipe1 = create_pipeline('xgb', XGBClassifier(class_weight='balanced', n_jobs=-1, random_state=0))\n",
    "pipe1.fit(X_train, y_train)\n",
    "preds1 = pipe1.predict(X_test)\n",
    "print_metrics(preds, y_test, pipe1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "roman-highland",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pipe2 = create_pipeline('svm', SVM())\n",
    "pipe2.fit(X_train, y_train)\n",
    "preds2 = pipe2.predict(X_test)\n",
    "print_metrics(preds, y_test, pipe2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "endless-suite",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(preds1, preds2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "coordinate-ecology",
   "metadata": {},
   "source": [
    "### feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "million-emphasis",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "#do code to support model\n",
    "#\"data\" is the X dataframe and model is the SKlearn object\n",
    "\n",
    "feats = {} # a dict to hold feature_name: feature_importance\n",
    "for feature, importance in zip(X.columns, pipe1['classifier'].feature_importances_):\n",
    "    feats[feature] = importance #add the name/value pair \n",
    "\n",
    "importances = pd.DataFrame.from_dict(feats, orient='index').rename(columns={0: 'importance'})\n",
    "importances.sort_values(by='importance').plot(kind='barh',figsize=(12,12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "annual-wallace",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "importances.sort_values(by='importance', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "macro-strip",
   "metadata": {},
   "source": [
    "## validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "advanced-platform",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = r'C:\\Users\\IsmailKaraman\\workspace\\data\\trendyol\\\\'\n",
    "test_raw = pd.read_csv(data_path+'test_data.csv')\n",
    "test_raw.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "educational-resistance",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test_raw.copy()\n",
    "test[['user_id', 'product_content_id', 'order_parent_id']] = test['id'].str.split('|',expand=True)\n",
    "test = test[['user_id', 'product_content_id', 'order_parent_id','expected']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hairy-railway",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "outside-advice",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "western-waters",
   "metadata": {},
   "outputs": [],
   "source": [
    "test['user_id'] = test['user_id'].astype('int64') \n",
    "test['order_parent_id'] = test['order_parent_id'].astype('int64')\n",
    "test['product_content_id'] = test['product_content_id'].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incorporate-noise",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.merge(test, null_df, on=['user_id', 'product_content_id', 'order_parent_id'], how='left')\n",
    "test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "harmful-placement",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "test_X = test_df[categorical_str+categorical_int+numerical+numerical2+passthrough]\n",
    "test_X.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mysterious-stanford",
   "metadata": {},
   "outputs": [],
   "source": [
    "expected = pipe1.predict(test_df[categorical_str+categorical_int+numerical+numerical2+passthrough])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sophisticated-billy",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_raw['expected'] = expected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bridal-portland",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_raw['expected'] = test_raw['expected'].astype('int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "korean-savings",
   "metadata": {},
   "outputs": [],
   "source": [
    "old_output = pd.read_csv('output.csv')\n",
    "accuracy_score(expected, old_output['expected'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tight-damage",
   "metadata": {},
   "outputs": [],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "green-runner",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_raw.to_csv('output.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "color-colors",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "subject-graduation",
   "metadata": {},
   "source": [
    "## auto ml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "governmental-astrology",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model_with_CV(X, y, model):\n",
    "    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=1)\n",
    "    scores = cross_validate(pipeline, X, y, scoring=['accuracy', 'f1_weighted'], n_jobs=-1, \n",
    "                        return_estimator=True, return_train_score=True, cv=cv)\n",
    "    # ['fit_time', 'score_time', 'estimator', 'test_accuracy', 'train_accuracy', 'test_f1_weighted', 'train_f1_weighted']\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "proprietary-morrison",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_metrics(y_pred, y_test, model):\n",
    "    print(\"Model results: \", type(model).__name__)\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(\"Confusion matrix:\")\n",
    "    cm = confusion_matrix(y_test,y_pred, labels= model.classes_)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm,display_labels= model.classes_)\n",
    "    disp.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sustainable-comedy",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pipeline_without_clf(clf_name, clf_object):\n",
    "    \n",
    "    numeric_transformer = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='median')),\n",
    "        ('scaler', StandardScaler())])\n",
    "\n",
    "    numeric_transformer2 = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='mean'))])\n",
    "    \n",
    "    categorical_str_transformer = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "        ('one-hot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "    \n",
    "    categorical_int_transformer = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='constant', fill_value=-99)),\n",
    "        ('one-hot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "    \n",
    "\n",
    "    preprocessor = ColumnTransformer(\n",
    "                                    transformers=[\n",
    "                                                  ('num1', numeric_transformer, numerical),\n",
    "                                                  ('num2', numeric_transformer2, numerical2),\n",
    "                                                  ('cat_str1', categorical_str_transformer, categorical_str),\n",
    "                                                  ('cat_int1', categorical_int_transformer, categorical_int),\n",
    "                                                  ], \n",
    "                                    remainder='passthrough')\n",
    "\n",
    "    pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                          ('f_selector', SelectKBest(f_classif, k='all')),\n",
    "                          (clf_name, clf_object)], verbose=False)\n",
    "    \n",
    "    return pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "subject-tracker",
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASSIFIERS = [\n",
    " ('AdaBoostClassifier', sklearn.ensemble._weight_boosting.AdaBoostClassifier),\n",
    " ('KNeighborsClassifier', sklearn.neighbors._classification.KNeighborsClassifier),\n",
    " ('LogisticRegression', sklearn.linear_model._logistic.LogisticRegression),\n",
    " ('XGBClassifier', XGBClassifier),\n",
    " ('LGBMClassifier', LGBMClassifier)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "national-valve",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = 10\n",
    "Accuracy_mean = []\n",
    "Accuracy_std = []\n",
    "F1_mean = []\n",
    "F1_std = []\n",
    "names = []\n",
    "TIME = []\n",
    "predictions = {}\n",
    "models = {}\n",
    "\n",
    "for name, model in tqdm(CLASSIFIERS):\n",
    "    start = time.time()\n",
    "    try:\n",
    "        if \"random_state\" in model().get_params().keys():\n",
    "            if \"class_weight\" in model().get_params().keys():\n",
    "                pipeline = create_pipeline_without_clf(\"classifier\", model(random_state=random_state, class_weight='balanced'))\n",
    "            else:\n",
    "                pipeline = create_pipeline_without_clf(\"classifier\", model(random_state=random_state))\n",
    "        else:\n",
    "            if \"class_weight\" in model().get_params().keys():\n",
    "                pipeline = create_pipeline_without_clf(\"classifier\", model(class_weight='balanced'))\n",
    "            else:\n",
    "                pipeline = create_pipeline_without_clf(\"classifier\", model())\n",
    "                \n",
    "                                   \n",
    "        results = evaluate_model_with_CV(X, y, model)\n",
    "                        \n",
    "        names.append(name)\n",
    "        Accuracy_mean.append(results['test_accuracy'].mean())\n",
    "        Accuracy_std.append(results['test_accuracy'].std())\n",
    "        F1_mean.append(results['test_f1_weighted'].mean())\n",
    "        F1_std.append(results['test_f1_weighted'].std())\n",
    "        TIME.append(results['fit_time'].mean())\n",
    "    \n",
    "    except Exception as exception:\n",
    "        print(name + \" model failed to execute\")\n",
    "        print(exception)\n",
    "                                   \n",
    "scores = pd.DataFrame(\n",
    "    {   \"Model\": names,\n",
    "        \"Accuracy Mean\": Accuracy_mean,\n",
    "        \"Accuracy Std\": Accuracy_std,\n",
    "        \"F1-Score Mean\": F1_mean,\n",
    "        \"F1-Score Std\": F1_std,\n",
    "        \"Time Taken\": TIME, })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "southern-scenario",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores.sort_values(by='F1-Score Mean', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "divided-allah",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_df = merged_df[merged_df['is_returned']==1].sample(50000, random_state=11)\n",
    "neg_df = merged_df[merged_df['is_returned']==0].sample(50000, random_state=11)\n",
    "\n",
    "model_df = pd.concat([pos_df, neg_df], axis=0)\n",
    "model_df.sample(frac=1)\n",
    "\n",
    "y = model_df['is_returned']\n",
    "X = model_df[categorical_str+categorical_int+numerical+numerical2+passthrough]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "respective-product",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = 10\n",
    "Accuracy_mean = []\n",
    "Accuracy_std = []\n",
    "F1_mean = []\n",
    "F1_std = []\n",
    "names = []\n",
    "TIME = []\n",
    "predictions = {}\n",
    "models = {}\n",
    "\n",
    "for name, model in tqdm(CLASSIFIERS):\n",
    "    start = time.time()\n",
    "    try:\n",
    "        if \"random_state\" in model().get_params().keys():\n",
    "            if \"class_weight\" in model().get_params().keys():\n",
    "                pipeline = create_pipeline_without_clf(\"classifier\", model(random_state=random_state, class_weight='balanced'))\n",
    "            else:\n",
    "                pipeline = create_pipeline_without_clf(\"classifier\", model(random_state=random_state))\n",
    "        else:\n",
    "            if \"class_weight\" in model().get_params().keys():\n",
    "                pipeline = create_pipeline_without_clf(\"classifier\", model(class_weight='balanced'))\n",
    "            else:\n",
    "                pipeline = create_pipeline_without_clf(\"classifier\", model())\n",
    "                \n",
    "                                   \n",
    "        results = evaluate_model_with_CV(X, y, model)\n",
    "                        \n",
    "        names.append(name)\n",
    "        Accuracy_mean.append(results['test_accuracy'].mean())\n",
    "        Accuracy_std.append(results['test_accuracy'].std())\n",
    "        F1_mean.append(results['test_f1_weighted'].mean())\n",
    "        F1_std.append(results['test_f1_weighted'].std())\n",
    "        TIME.append(results['fit_time'].mean())\n",
    "    \n",
    "    except Exception as exception:\n",
    "        print(name + \" model failed to execute\")\n",
    "        print(exception)\n",
    "                                   \n",
    "scores2 = pd.DataFrame(\n",
    "    {   \"Model\": names,\n",
    "        \"Accuracy Mean\": Accuracy_mean,\n",
    "        \"Accuracy Std\": Accuracy_std,\n",
    "        \"F1-Score Mean\": F1_mean,\n",
    "        \"F1-Score Std\": F1_std,\n",
    "        \"Time Taken\": TIME, })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "starting-wales",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores2.sort_values(by='F1-Score Mean', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "worldwide-sixth",
   "metadata": {},
   "outputs": [],
   "source": [
    "XGBClassifier\n",
    "LGBMClassifier"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
